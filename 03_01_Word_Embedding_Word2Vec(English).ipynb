{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-01. Word Embedding - Word2Vec(English)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJOLD2Yq/2Zr4FAiDNofv+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimminsu-ds/Deep-Learning-NLP-using-Tensorflow/blob/main/03_01_Word_Embedding_Word2Vec(English).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mbBseaCjXFW"
      },
      "source": [
        "# 러닝스푼즈 - Tensorflow를 활용한 딥러닝 자연어처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLDx0D87iO11"
      },
      "source": [
        "import re\n",
        "from lxml import etree\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrC7lYpuja8A",
        "outputId": "4d3ff409-b05d-4866-efeb-0903e4d1aece"
      },
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFU54JsCjgBN"
      },
      "source": [
        "## 데이터 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yimJLZEUjbj1",
        "outputId": "32acd355-02e7-4af6-c18e-0bc37e846bf4"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")\n",
        "\n",
        "targetXML = open(\"ted_en-20160408.xml\", 'r', encoding=\"UTF8\")\n",
        "target_text = etree.parse(targetXML)\n",
        "\n",
        "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
        "parse_text = '\\n'.join(target_text.xpath(\"//content/text()\"))\n",
        "print(parse_text[:96])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are two reasons companies fail: they only do more of the same, or they only do what's new.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbU0o4_mjjvd"
      },
      "source": [
        "## 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhhlU_0ejeoP",
        "outputId": "32a70350-510f-41f8-e4f9-40ab1ad3349d"
      },
      "source": [
        "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거\n",
        "# 해당 코드는 괄호로 구성된 내용을 제거\n",
        "content_text = re.sub(r'\\([%)]*\\)', '', parse_text)\n",
        "print(content_text[:95])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are two reasons companies fail: they only do more of the same, or they only do what's new.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ece8kLzDjk7H"
      },
      "source": [
        "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화 수행\n",
        "sent_text = sent_tokenize(content_text)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d1DHgpYj-sL"
      },
      "source": [
        "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "  tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "  normalized_text.append(tokens)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg-WVb2Pj_Za"
      },
      "source": [
        "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxSSaLL1kBRZ",
        "outputId": "a55fa1f5-f38d-4923-9b10-61fd292c1532"
      },
      "source": [
        "print(\"총 샘플의 개수: {}\".format(len(result)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수: 273649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrJjYwbpkB8a",
        "outputId": "9d1641ec-07dd-4d70-f73b-937d83ab1a76"
      },
      "source": [
        "for line in result[:3]:\n",
        "  print(line)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
            "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
            "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XiMff2YkGBq"
      },
      "source": [
        "## Word2Vec 임베딩\n",
        "[Gensim Word2Vec API](https://radimrehurek.com/gensim/models/word2vec.html)\n",
        "- size: 워드 벡터의 특징값. 즉, 임베딩 된 벡터의 차원\n",
        "- window: 컨텍스트 윈도우 크기\n",
        "- min_count: 단어 최소 빈도수 제한(빈도가 적은 단어들은 학습하지 않는다)\n",
        "- workers: 학습을 위한 프로세스 수\n",
        "- sg\n",
        "  - 0: CBOW\n",
        "  - 1: Skip-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaE-06HMkC2F"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(sentences = result, size = 100, window = 5, min_count = 5, workers = 4, sg = 0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLRfa48VkTnS",
        "outputId": "916ff9ef-e853-48f7-9c9c-57a6b79ff9c4"
      },
      "source": [
        "model_result = model.wv.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.8565999865531921), ('guy', 0.8201879262924194), ('lady', 0.7860196828842163), ('girl', 0.767379641532898), ('soldier', 0.7628076076507568), ('boy', 0.7621582746505737), ('gentleman', 0.736214280128479), ('kid', 0.7107130289077759), ('poet', 0.6882884502410889), ('surgeon', 0.6674830913543701)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVPFq-8TkfHG"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model.wv.save_word2vec_format(\"eng_w2v\") # 모델 저장\n",
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey9xT3yokf8y",
        "outputId": "704161c6-b1fc-4bd0-b7de-88c3dda74d2e"
      },
      "source": [
        "model_result = loaded_model.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.8565999865531921), ('guy', 0.8201879262924194), ('lady', 0.7860196828842163), ('girl', 0.767379641532898), ('soldier', 0.7628076076507568), ('boy', 0.7621582746505737), ('gentleman', 0.736214280128479), ('kid', 0.7107130289077759), ('poet', 0.6882884502410889), ('surgeon', 0.6674830913543701)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAnUasI7kuy6"
      },
      "source": [
        "## Visualization\n",
        "- eng_w2v라는 Word2Vec 모델이 이미 존재한다는 가정 하에 아래 커맨드를 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "byGarFH7lDxM",
        "outputId": "8fd79783-7229-4fba-b2d8-c345bc25806f"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEC-kQJtkhOc",
        "outputId": "08c4463d-4f44-47bd-9f0d-518e74e67e74"
      },
      "source": [
        "!python -m gensim.scripts.word2vec2tensor --input eng_w2v --output eng_w2v"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-19 12:46:07,984 - word2vec2tensor - INFO - running /usr/local/lib/python3.7/dist-packages/gensim/scripts/word2vec2tensor.py --input eng_w2v --output eng_w2v\n",
            "2021-10-19 12:46:07,985 - utils_any2vec - INFO - loading projection weights from eng_w2v\n",
            "2021-10-19 12:46:10,568 - utils_any2vec - INFO - loaded (21662, 100) matrix from eng_w2v\n",
            "2021-10-19 12:46:12,611 - word2vec2tensor - INFO - 2D tensor file saved to eng_w2v_tensor.tsv\n",
            "2021-10-19 12:46:12,611 - word2vec2tensor - INFO - Tensor metadata file saved to eng_w2v_metadata.tsv\n",
            "2021-10-19 12:46:12,614 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tZEaStAlor2"
      },
      "source": [
        "### [Embedding Projector](https://projector.tensorflow.org/)\n",
        "  - 위 Choose file 버튼 클릭\n",
        "  - eng_w2v_tensor.tsv 파일 업로드\n",
        "  - 아래 Choose file 버튼 클릭\n",
        "  - eng_w2v_metadata.tsv 파일 업로드\n",
        "  - 두 파일을 업로드하면 워드 임베딩 모델이 시각화"
      ]
    }
  ]
}