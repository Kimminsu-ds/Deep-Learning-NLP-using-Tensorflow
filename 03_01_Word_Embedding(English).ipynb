{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-01. Word Embedding(English)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtg07lV6kbXzoTr1JGDkbe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimminsu-ds/Deep-Learning-NLP-using-Tensorflow/blob/main/03_01_Word_Embedding(English).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mbBseaCjXFW"
      },
      "source": [
        "# 러닝스푼즈 - Tensorflow를 활용한 딥러닝 자연어처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLDx0D87iO11"
      },
      "source": [
        "import re\n",
        "from lxml import etree\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrC7lYpuja8A",
        "outputId": "4d3ff409-b05d-4866-efeb-0903e4d1aece"
      },
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFU54JsCjgBN"
      },
      "source": [
        "## 데이터 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yimJLZEUjbj1",
        "outputId": "32acd355-02e7-4af6-c18e-0bc37e846bf4"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")\n",
        "\n",
        "targetXML = open(\"ted_en-20160408.xml\", 'r', encoding=\"UTF8\")\n",
        "target_text = etree.parse(targetXML)\n",
        "\n",
        "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
        "parse_text = '\\n'.join(target_text.xpath(\"//content/text()\"))\n",
        "print(parse_text[:96])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are two reasons companies fail: they only do more of the same, or they only do what's new.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbU0o4_mjjvd"
      },
      "source": [
        "## 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhhlU_0ejeoP",
        "outputId": "32a70350-510f-41f8-e4f9-40ab1ad3349d"
      },
      "source": [
        "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거\n",
        "# 해당 코드는 괄호로 구성된 내용을 제거\n",
        "content_text = re.sub(r'\\([%)]*\\)', '', parse_text)\n",
        "print(content_text[:95])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are two reasons companies fail: they only do more of the same, or they only do what's new.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ece8kLzDjk7H"
      },
      "source": [
        "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화 수행\n",
        "sent_text = sent_tokenize(content_text)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d1DHgpYj-sL"
      },
      "source": [
        "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "  tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "  normalized_text.append(tokens)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg-WVb2Pj_Za"
      },
      "source": [
        "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxSSaLL1kBRZ",
        "outputId": "a55fa1f5-f38d-4923-9b10-61fd292c1532"
      },
      "source": [
        "print(\"총 샘플의 개수: {}\".format(len(result)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수: 273649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrJjYwbpkB8a",
        "outputId": "9d1641ec-07dd-4d70-f73b-937d83ab1a76"
      },
      "source": [
        "for line in result[:3]:\n",
        "  print(line)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
            "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
            "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XiMff2YkGBq"
      },
      "source": [
        "## Word2Vec 임베딩\n",
        "[Gensim Word2Vec API](https://radimrehurek.com/gensim/models/word2vec.html)\n",
        "- size: 워드 벡터의 특징값. 즉, 임베딩 된 벡터의 차원\n",
        "- window: 컨텍스트 윈도우 크기\n",
        "- min_count: 단어 최소 빈도수 제한(빈도가 적은 단어들은 학습하지 않는다)\n",
        "- workers: 학습을 위한 프로세스 수\n",
        "- sg\n",
        "  - 0: CBOW\n",
        "  - 1: Skip-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaE-06HMkC2F"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(sentences = result, size = 100, window = 5, min_count = 5, workers = 4, sg = 0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLRfa48VkTnS",
        "outputId": "916ff9ef-e853-48f7-9c9c-57a6b79ff9c4"
      },
      "source": [
        "model_result = model.wv.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.8565999865531921), ('guy', 0.8201879262924194), ('lady', 0.7860196828842163), ('girl', 0.767379641532898), ('soldier', 0.7628076076507568), ('boy', 0.7621582746505737), ('gentleman', 0.736214280128479), ('kid', 0.7107130289077759), ('poet', 0.6882884502410889), ('surgeon', 0.6674830913543701)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVPFq-8TkfHG"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model.wv.save_word2vec_format(\"eng_w2v\") # 모델 저장\n",
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey9xT3yokf8y",
        "outputId": "704161c6-b1fc-4bd0-b7de-88c3dda74d2e"
      },
      "source": [
        "model_result = loaded_model.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.8565999865531921), ('guy', 0.8201879262924194), ('lady', 0.7860196828842163), ('girl', 0.767379641532898), ('soldier', 0.7628076076507568), ('boy', 0.7621582746505737), ('gentleman', 0.736214280128479), ('kid', 0.7107130289077759), ('poet', 0.6882884502410889), ('surgeon', 0.6674830913543701)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAnUasI7kuy6"
      },
      "source": [
        "## Visualization\n",
        "- eng_w2v라는 Word2Vec 모델이 이미 존재한다는 가정 하에 아래 커맨드를 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "byGarFH7lDxM",
        "outputId": "8fd79783-7229-4fba-b2d8-c345bc25806f"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEC-kQJtkhOc",
        "outputId": "08c4463d-4f44-47bd-9f0d-518e74e67e74"
      },
      "source": [
        "!python -m gensim.scripts.word2vec2tensor --input eng_w2v --output eng_w2v"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-19 12:46:07,984 - word2vec2tensor - INFO - running /usr/local/lib/python3.7/dist-packages/gensim/scripts/word2vec2tensor.py --input eng_w2v --output eng_w2v\n",
            "2021-10-19 12:46:07,985 - utils_any2vec - INFO - loading projection weights from eng_w2v\n",
            "2021-10-19 12:46:10,568 - utils_any2vec - INFO - loaded (21662, 100) matrix from eng_w2v\n",
            "2021-10-19 12:46:12,611 - word2vec2tensor - INFO - 2D tensor file saved to eng_w2v_tensor.tsv\n",
            "2021-10-19 12:46:12,611 - word2vec2tensor - INFO - Tensor metadata file saved to eng_w2v_metadata.tsv\n",
            "2021-10-19 12:46:12,614 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tZEaStAlor2"
      },
      "source": [
        "### [Embedding Projector](https://projector.tensorflow.org/)\n",
        "  - 위 Choose file 버튼 클릭\n",
        "  - eng_w2v_tensor.tsv 파일 업로드\n",
        "  - 아래 Choose file 버튼 클릭\n",
        "  - eng_w2v_metadata.tsv 파일 업로드\n",
        "  - 두 파일을 업로드하면 워드 임베딩 모델이 시각화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfCIW0ITqraN"
      },
      "source": [
        "## FastText\n",
        "- Word2Vec의 OOV 문제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "e4L9PWqoqrN6",
        "outputId": "08f859a6-01f4-490e-ca4d-afec7d3b9998"
      },
      "source": [
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # Word2Vec 모델 로드\n",
        "model_result = loaded_model.most_similar(\"overacting\")\n",
        "print(model_result)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-35e5b08cb143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eng_w2v\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Word2Vec 모델 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overacting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'overacting' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gT_F1g-qqb9",
        "outputId": "3f6b0ebb-68bc-4a74-a7b8-a6f1dca8edde"
      },
      "source": [
        "model_result = loaded_model.most_similar(\"memory\")\n",
        "print(model_result)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('brain', 0.7454793453216553), ('body', 0.7242261171340942), ('imagination', 0.6850780248641968), ('perception', 0.6834355592727661), ('intuition', 0.6751922369003296), ('function', 0.668582558631897), ('activity', 0.6680774688720703), ('consciousness', 0.6617116332054138), ('strength', 0.6600881218910217), ('tissue', 0.6555130481719971)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "zn0cARjrogxH",
        "outputId": "6af89c7f-2cdb-45c0-f1c6-b46ce4002467"
      },
      "source": [
        "model_result = loaded_model.most_similar(\"memorry\")\n",
        "print(model_result)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ca1d1c0d0c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memorry\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'memorry' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "zxOC0AjNrFPe",
        "outputId": "772557d6-f2b7-4d84-9faa-25160d24a5aa"
      },
      "source": [
        "model_result = loaded_model.most_similar(\"electrofishing\")\n",
        "print(model_result)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a16378e6d82e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"electrofishing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'electrofishing' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbNeRzjarIMC"
      },
      "source": [
        "### FastText Embedding\n",
        "[Gensim FastText API](https://radimrehurek.com/gensim/models/fasttext.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlWqyg-9rGWf"
      },
      "source": [
        "from gensim.models import FastText\n",
        "fasttext_model = FastText(result, size=100, window=5, min_count=5, workers=4, sg=1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilXs4BRHrTil",
        "outputId": "ca3f38e0-dff0-42da-d1ac-fcd789d3687a"
      },
      "source": [
        "fasttext_model.most_similar(\"overacting\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('interacting', 0.8681800961494446),\n",
              " ('manipulating', 0.8505892753601074),\n",
              " ('subtracting', 0.8299702405929565),\n",
              " ('distracting', 0.8239017724990845),\n",
              " ('impacting', 0.8165470957756042),\n",
              " ('contracting', 0.8099298477172852),\n",
              " ('extracting', 0.7972195148468018),\n",
              " ('acting', 0.7911936640739441),\n",
              " ('behaving', 0.7858031988143921),\n",
              " ('cooperating', 0.7831429243087769)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTJwY3WFrcFg",
        "outputId": "a416c5c2-4906-4de0-d1cd-3e6d78f19aed"
      },
      "source": [
        "fasttext_model.most_similar(\"memorry\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('memo', 0.8432082533836365),\n",
              " ('memory', 0.769365668296814),\n",
              " ('memorize', 0.7666587829589844),\n",
              " ('memoir', 0.7558838129043579),\n",
              " ('nemo', 0.7090966105461121),\n",
              " ('emory', 0.6855215430259705),\n",
              " ('dereck', 0.6816719770431519),\n",
              " ('memorial', 0.6809093952178955),\n",
              " ('memoirs', 0.6794471740722656),\n",
              " ('forgery', 0.6784298419952393)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgj37nfxrdLZ",
        "outputId": "5c03bf0c-3332-4fcb-92e1-17554137eaee"
      },
      "source": [
        "fasttext_model.most_similar(\"electrofishing\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('electrolux', 0.8118401765823364),\n",
              " ('electro', 0.7946038246154785),\n",
              " ('electrolyte', 0.7906200289726257),\n",
              " ('electrochemical', 0.7681560516357422),\n",
              " ('electroshock', 0.766903281211853),\n",
              " ('electron', 0.758313775062561),\n",
              " ('airbus', 0.75740647315979),\n",
              " ('electric', 0.7544244527816772),\n",
              " ('petroleum', 0.7492835521697998),\n",
              " ('electrogram', 0.7476785182952881)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh06YtWMsIfg"
      },
      "source": [
        "## Glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGSA1W4dreQY",
        "outputId": "b5447e68-a264-4959-b20f-b3df9c9de8fe"
      },
      "source": [
        "!pip install glove_python_binary"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting glove_python_binary\n",
            "  Downloading glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 686 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 696 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 706 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 716 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 727 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 737 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 747 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 757 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 768 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 778 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 788 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 798 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 808 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 819 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 829 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 839 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 849 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 860 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 870 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 880 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 890 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 901 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 911 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 921 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 931 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 942 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 948 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.4.1)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjY1qL8wsJ0m",
        "outputId": "4d1605f3-0fd3-4748-b849-17d642f83dff"
      },
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "# 훈련 데이터로부터 GloVE에서 사용할 동시 등장 행렬 생성\n",
        "corpus = Corpus()\n",
        "corpus.fit(result, window=5)\n",
        "\n",
        "# 학습에 이용할 쓰레드의 개수는 4개, 에포크는 20으로 설정\n",
        "glove = Glove(no_components=100, learning_rate=0.05)\n",
        "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 20 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF5zFeHgsK2l",
        "outputId": "baf6fad3-ad58-47f7-ee43-9b6535b357d6"
      },
      "source": [
        "model_result1 = glove.most_similar(\"man\")\n",
        "print(model_result1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.9561557091918471), ('guy', 0.8764421784552235), ('girl', 0.8723682461981662), ('boy', 0.8437721102413391)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MN3rflbsaKZ",
        "outputId": "f99e2ec7-764d-43ca-fbee-2c1439ca3bb5"
      },
      "source": [
        "model_result2 = glove.most_similar(\"boy\")\n",
        "print(model_result2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('girl', 0.9457186703096012), ('woman', 0.8694451439550647), ('man', 0.843772110241339), ('kid', 0.8400019102507477)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzOYePnOsawg",
        "outputId": "cabe5ff1-3597-43b3-c4bc-72c317f14db7"
      },
      "source": [
        "model_result3 = glove.most_similar(\"university\")\n",
        "print(model_result3)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('harvard', 0.8885466417077313), ('mit', 0.8467218265307618), ('stanford', 0.8293999937217268), ('cambridge', 0.8249610860364013)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOwg9ol5sbXC",
        "outputId": "b8c2e121-9966-49b1-fea5-f64c7ec91870"
      },
      "source": [
        "model_result4 = glove.most_similar(\"water\")\n",
        "print(model_result4)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('clean', 0.8569630638984247), ('fresh', 0.8388016032558542), ('air', 0.8299769157043785), ('food', 0.8238028760017486)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtjfIRIUscF5",
        "outputId": "c24ce7d9-60f2-4d38-b793-ae4f059a8a67"
      },
      "source": [
        "model_result5 = glove.most_similar(\"physics\")\n",
        "print(model_result5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('economics', 0.906194820720972), ('chemistry', 0.8805944669589155), ('simplicity', 0.8641558617129502), ('beauty', 0.8591936877994484)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmXjufKYsdAp",
        "outputId": "4eb01ffd-b42e-4483-e103-89faaac37886"
      },
      "source": [
        "model_result6 = glove.most_similar(\"muscle\")\n",
        "print(model_result6)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tissue', 0.8528104455396867), ('nerve', 0.816419353092629), ('skeletal', 0.7969838320863409), ('bone', 0.7723693962517788)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBw2L_-_sd2L",
        "outputId": "6a021103-9caa-4bb4-825c-e18f166904e8"
      },
      "source": [
        "model_result7 = glove.most_similar(\"clean\")\n",
        "print(model_result7)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('fresh', 0.8600574993010727), ('water', 0.8569630638984247), ('heat', 0.8065985020930019), ('wind', 0.7973389015673037)]\n"
          ]
        }
      ]
    }
  ]
}